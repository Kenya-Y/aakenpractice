{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import sys,os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#リストで結果を返す関数\n",
    "def get_file(dir_path):\n",
    "    filenames = os.listdir(dir_path)\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#画像表示関数(100,100でreshapeして使うこと）\n",
    "def img_show(img):\n",
    "    pil_img = Image.fromarray(np.uint8(img))\n",
    "    pil_img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練用データの配列格納"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#写真のパスをそれぞれ指定する\n",
    "masami_jpg    = \"train/masami_train/\"\n",
    "kasumi_jpg    = \"train/kasumi_train/\"\n",
    "minami_jpg    = \"train/minami_train/\"\n",
    "pic_masami    = get_file(masami_jpg)\n",
    "pic_kasumi    = get_file(kasumi_jpg)\n",
    "pic_minami    = get_file(minami_jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DS_Storeをリストから除外\n",
    "pic_masami.remove('.DS_Store')\n",
    "pic_kasumi.remove('.DS_Store')\n",
    "pic_minami.remove('.DS_Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['masami131.jpg',\n",
       " 'masami125.jpg',\n",
       " 'masami119.jpg',\n",
       " 'masami247.jpg',\n",
       " 'masami253.jpg',\n",
       " 'masami24.jpg',\n",
       " 'masami30.jpg',\n",
       " 'masami18.jpg',\n",
       " 'masami19.jpg',\n",
       " 'masami31.jpg',\n",
       " 'masami25.jpg',\n",
       " 'masami252.jpg',\n",
       " 'masami246.jpg',\n",
       " 'masami118.jpg',\n",
       " 'masami124.jpg',\n",
       " 'masami130.jpg',\n",
       " 'masami126.jpg',\n",
       " 'masami132.jpg',\n",
       " 'masami250.jpg',\n",
       " 'masami244.jpg',\n",
       " 'masami33.jpg',\n",
       " 'masami27.jpg',\n",
       " 'masami26.jpg',\n",
       " 'masami32.jpg',\n",
       " 'masami245.jpg',\n",
       " 'masami251.jpg',\n",
       " 'masami133.jpg',\n",
       " 'masami127.jpg',\n",
       " 'masami123.jpg',\n",
       " 'masami137.jpg',\n",
       " 'masami255.jpg',\n",
       " 'masami241.jpg',\n",
       " 'masami36.jpg',\n",
       " 'masami22.jpg',\n",
       " 'masami23.jpg',\n",
       " 'masami37.jpg',\n",
       " 'masami240.jpg',\n",
       " 'masami254.jpg',\n",
       " 'masami136.jpg',\n",
       " 'masami122.jpg',\n",
       " 'masami108.jpg',\n",
       " 'masami134.jpg',\n",
       " 'masami120.jpg',\n",
       " 'masami242.jpg',\n",
       " 'masami256.jpg',\n",
       " 'masami21.jpg',\n",
       " 'masami35.jpg',\n",
       " 'masami34.jpg',\n",
       " 'masami20.jpg',\n",
       " 'masami257.jpg',\n",
       " 'masami243.jpg',\n",
       " 'masami121.jpg',\n",
       " 'masami135.jpg',\n",
       " 'masami109.jpg',\n",
       " 'masami152.jpg',\n",
       " 'masami146.jpg',\n",
       " 'masami191.jpg',\n",
       " 'masami185.jpg',\n",
       " 'masami224.jpg',\n",
       " 'masami2.jpg',\n",
       " 'masami230.jpg',\n",
       " 'masami218.jpg',\n",
       " 'masami47.jpg',\n",
       " 'masami53.jpg',\n",
       " 'masami84.jpg',\n",
       " 'masami90.jpg',\n",
       " 'masami91.jpg',\n",
       " 'masami85.jpg',\n",
       " 'masami52.jpg',\n",
       " 'masami46.jpg',\n",
       " 'masami219.jpg',\n",
       " 'masami3.jpg',\n",
       " 'masami231.jpg',\n",
       " 'masami225.jpg',\n",
       " 'masami184.jpg',\n",
       " 'masami190.jpg',\n",
       " 'masami147.jpg',\n",
       " 'masami153.jpg',\n",
       " 'masami145.jpg',\n",
       " 'masami151.jpg',\n",
       " 'masami179.jpg',\n",
       " 'masami186.jpg',\n",
       " 'masami192.jpg',\n",
       " 'masami233.jpg',\n",
       " 'masami1.jpg',\n",
       " 'masami227.jpg',\n",
       " 'masami50.jpg',\n",
       " 'masami44.jpg',\n",
       " 'masami78.jpg',\n",
       " 'masami93.jpg',\n",
       " 'masami87.jpg',\n",
       " 'masami86.jpg',\n",
       " 'masami92.jpg',\n",
       " 'masami79.jpg',\n",
       " 'masami45.jpg',\n",
       " 'masami51.jpg',\n",
       " 'masami226.jpg',\n",
       " 'masami232.jpg',\n",
       " 'masami193.jpg',\n",
       " 'masami187.jpg',\n",
       " 'masami178.jpg',\n",
       " 'masami150.jpg',\n",
       " 'masami144.jpg',\n",
       " 'masami168.jpg',\n",
       " 'masami140.jpg',\n",
       " 'masami154.jpg',\n",
       " 'masami183.jpg',\n",
       " 'masami197.jpg',\n",
       " 'masami4.jpg',\n",
       " 'masami236.jpg',\n",
       " 'masami222.jpg',\n",
       " 'masami69.jpg',\n",
       " 'masami55.jpg',\n",
       " 'masami41.jpg',\n",
       " 'masami96.jpg',\n",
       " 'masami82.jpg',\n",
       " 'masami83.jpg',\n",
       " 'masami97.jpg',\n",
       " 'masami40.jpg',\n",
       " 'masami54.jpg',\n",
       " 'masami68.jpg',\n",
       " 'masami223.jpg',\n",
       " 'masami5.jpg',\n",
       " 'masami237.jpg',\n",
       " 'masami196.jpg',\n",
       " 'masami182.jpg',\n",
       " 'masami155.jpg',\n",
       " 'masami141.jpg',\n",
       " 'masami169.jpg',\n",
       " 'masami157.jpg',\n",
       " 'masami143.jpg',\n",
       " 'masami194.jpg',\n",
       " 'masami180.jpg',\n",
       " 'masami209.jpg',\n",
       " 'masami221.jpg',\n",
       " 'masami235.jpg',\n",
       " 'masami7.jpg',\n",
       " 'masami42.jpg',\n",
       " 'masami56.jpg',\n",
       " 'masami81.jpg',\n",
       " 'masami95.jpg',\n",
       " 'masami94.jpg',\n",
       " 'masami80.jpg',\n",
       " 'masami57.jpg',\n",
       " 'masami43.jpg',\n",
       " 'masami234.jpg',\n",
       " 'masami6.jpg',\n",
       " 'masami220.jpg',\n",
       " 'masami208.jpg',\n",
       " 'masami181.jpg',\n",
       " 'masami195.jpg',\n",
       " 'masami142.jpg',\n",
       " 'masami156.jpg',\n",
       " 'masami173.jpg',\n",
       " 'masami167.jpg',\n",
       " 'masami198.jpg',\n",
       " 'masami205.jpg',\n",
       " 'masami211.jpg',\n",
       " 'masami239.jpg',\n",
       " 'masami66.jpg',\n",
       " 'masami72.jpg',\n",
       " 'masami99.jpg',\n",
       " 'masami98.jpg',\n",
       " 'masami73.jpg',\n",
       " 'masami67.jpg',\n",
       " 'masami238.jpg',\n",
       " 'masami210.jpg',\n",
       " 'masami204.jpg',\n",
       " 'masami199.jpg',\n",
       " 'masami166.jpg',\n",
       " 'masami172.jpg',\n",
       " 'masami164.jpg',\n",
       " 'masami170.jpg',\n",
       " 'masami158.jpg',\n",
       " 'masami212.jpg',\n",
       " 'masami206.jpg',\n",
       " 'masami8.jpg',\n",
       " 'masami71.jpg',\n",
       " 'masami65.jpg',\n",
       " 'masami59.jpg',\n",
       " 'masami58.jpg',\n",
       " 'masami64.jpg',\n",
       " 'masami70.jpg',\n",
       " 'masami9.jpg',\n",
       " 'masami207.jpg',\n",
       " 'masami213.jpg',\n",
       " 'masami159.jpg',\n",
       " 'masami171.jpg',\n",
       " 'masami165.jpg',\n",
       " 'masami149.jpg',\n",
       " 'masami161.jpg',\n",
       " 'masami175.jpg',\n",
       " 'masami217.jpg',\n",
       " 'masami203.jpg',\n",
       " 'masami48.jpg',\n",
       " 'masami74.jpg',\n",
       " 'masami60.jpg',\n",
       " 'masami61.jpg',\n",
       " 'masami75.jpg',\n",
       " 'masami49.jpg',\n",
       " 'masami202.jpg',\n",
       " 'masami216.jpg',\n",
       " 'masami174.jpg',\n",
       " 'masami160.jpg',\n",
       " 'masami148.jpg',\n",
       " 'masami176.jpg',\n",
       " 'masami162.jpg',\n",
       " 'masami189.jpg',\n",
       " 'masami228.jpg',\n",
       " 'masami200.jpg',\n",
       " 'masami214.jpg',\n",
       " 'masami63.jpg',\n",
       " 'masami77.jpg',\n",
       " 'masami88.jpg',\n",
       " 'masami89.jpg',\n",
       " 'masami76.jpg',\n",
       " 'masami62.jpg',\n",
       " 'masami215.jpg',\n",
       " 'masami201.jpg',\n",
       " 'masami229.jpg',\n",
       " 'masami188.jpg',\n",
       " 'masami163.jpg',\n",
       " 'masami177.jpg',\n",
       " 'masami110.jpg',\n",
       " 'masami104.jpg',\n",
       " 'masami138.jpg',\n",
       " 'masami266.jpg',\n",
       " 'masami11.jpg',\n",
       " 'masami39.jpg',\n",
       " 'masami38.jpg',\n",
       " 'masami10.jpg',\n",
       " 'masami267.jpg',\n",
       " 'masami139.jpg',\n",
       " 'masami105.jpg',\n",
       " 'masami111.jpg',\n",
       " 'masami107.jpg',\n",
       " 'masami113.jpg',\n",
       " 'masami265.jpg',\n",
       " 'masami259.jpg',\n",
       " 'masami12.jpg',\n",
       " 'masami13.jpg',\n",
       " 'masami258.jpg',\n",
       " 'masami264.jpg',\n",
       " 'masami112.jpg',\n",
       " 'masami106.jpg',\n",
       " 'masami102.jpg',\n",
       " 'masami116.jpg',\n",
       " 'masami248.jpg',\n",
       " 'masami260.jpg',\n",
       " 'masami17.jpg',\n",
       " 'masami16.jpg',\n",
       " 'masami261.jpg',\n",
       " 'masami249.jpg',\n",
       " 'masami117.jpg',\n",
       " 'masami103.jpg',\n",
       " 'masami129.jpg',\n",
       " 'masami115.jpg',\n",
       " 'masami101.jpg',\n",
       " 'masami263.jpg',\n",
       " 'masami28.jpg',\n",
       " 'masami14.jpg',\n",
       " 'masami15.jpg',\n",
       " 'masami29.jpg',\n",
       " 'masami262.jpg',\n",
       " 'masami100.jpg',\n",
       " 'masami114.jpg',\n",
       " 'masami128.jpg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#リストの確認\n",
    "pic_masami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#画像・ラベルを配列に格納する(訓練用画像)\n",
    "#長澤まさみ：0、有村架純：1、浜辺美波：２\n",
    "\n",
    "datas_pic = []\n",
    "datas_label = []\n",
    "\n",
    "#長澤まさみの画像を配列に格納する\n",
    "for i in pic_masami:\n",
    "    #写真格納\n",
    "    #写真をdataに格納する\n",
    "    data = np.array(Image.open(masami_jpg + i).convert(\"L\"), np.float32)\n",
    "    #画像の形式を(100,100)→(1,100,100)に変更\n",
    "    data = data.reshape(-1,100,100)\n",
    "    #画像の次元を追加（axisに指定した成分に次元を追加）\n",
    "    data_expanded = np.expand_dims(data,axis=0)\n",
    "    #画像を配列に格納する\n",
    "    datas_pic.append(data_expanded)\n",
    "    #Numpy配列に格納する\n",
    "    train_datas = np.concatenate(datas_pic,axis=0)\n",
    "    #ラベル格納\n",
    "    label = 0\n",
    "    #ラベルの次元を追加する\n",
    "    label_expanded = np.expand_dims(label,axis=0)\n",
    "    #ラベルを配列に格納する\n",
    "    datas_label.append(label_expanded)\n",
    "    #Numpy配列に格納する\n",
    "    label_datas = np.concatenate(datas_label,axis=0)\n",
    "    \n",
    "#有村架純の画像を配列に格納する\n",
    "for i in pic_kasumi:\n",
    "    #写真をdataに格納する\n",
    "    data = np.array(Image.open(kasumi_jpg + i).convert(\"L\"), np.float32)\n",
    "    #形式を(100,100)→(1,100,100)に変更\n",
    "    data = data.reshape(-1,100,100)\n",
    "    #次元を追加（axisに指定した成分に次元を追加）\n",
    "    data_expanded = np.expand_dims(data,axis=0)\n",
    "    #配列に格納する\n",
    "    datas_pic.append(data_expanded)\n",
    "    train_datas = np.concatenate(datas_pic,axis=0)\n",
    "    #ラベル格納\n",
    "    label = 1\n",
    "    #ラベルの次元を追加する\n",
    "    label_expanded = np.expand_dims(label,axis=0)\n",
    "    #ラベルを配列に格納する\n",
    "    datas_label.append(label_expanded)\n",
    "    #Numpy配列に格納する\n",
    "    label_datas = np.concatenate(datas_label,axis=0)\n",
    "\n",
    "#浜辺美波の画像を配列に格納する\n",
    "for i in pic_minami:\n",
    "    #写真格納\n",
    "    #写真をdataに格納する\n",
    "    data = np.array(Image.open(minami_jpg + i).convert(\"L\"), np.float32)\n",
    "    #画像の形式を(100,100)→(1,100,100)に変更\n",
    "    data = data.reshape(-1,100,100)\n",
    "    #画像の次元を追加（axisに指定した成分に次元を追加）\n",
    "    data_expanded = np.expand_dims(data,axis=0)\n",
    "    #画像を配列に格納する\n",
    "    datas_pic.append(data_expanded)\n",
    "    #Numpy配列に格納する\n",
    "    train_datas = np.concatenate(datas_pic,axis=0)\n",
    "    #ラベル格納\n",
    "    label = 2\n",
    "    #ラベルの次元を追加する\n",
    "    label_expanded = np.expand_dims(label,axis=0)\n",
    "    #ラベルを配列に格納する\n",
    "    datas_label.append(label_expanded)\n",
    "    #Numpy配列に格納する\n",
    "    label_datas = np.concatenate(datas_label,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,t_train)=(train_datas,label_datas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テスト用データの配列格納"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#写真のパスをそれぞれ指定する\n",
    "masami_jpg    = \"train/masami_test/\"\n",
    "kasumi_jpg    = \"train/kasumi_test/\"\n",
    "minami_jpg    = \"train/minami_test/\"\n",
    "pic_masami2    = get_file(masami_jpg)\n",
    "pic_kasumi2    = get_file(kasumi_jpg)\n",
    "pic_minami2    = get_file(minami_jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-419b92b3908d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpic_masami2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.DS_Store'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpic_kasumi2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.DS_Store'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpic_minami2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.DS_Store'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "#DS_Storeをリストから除外\n",
    "pic_masami2.remove('.DS_Store')\n",
    "pic_kasumi2.remove('.DS_Store')\n",
    "pic_minami2.remove('.DS_Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['masami_test49.jpg',\n",
       " 'masami_test61.jpg',\n",
       " 'masami_test8.jpg',\n",
       " 'masami_test9.jpg',\n",
       " 'masami_test60.jpg',\n",
       " 'masami_test48.jpg',\n",
       " 'masami_test62.jpg',\n",
       " 'masami_test63.jpg',\n",
       " 'masami_test67.jpg',\n",
       " 'masami_test66.jpg',\n",
       " 'masami_test64.jpg',\n",
       " 'masami_test70.jpg',\n",
       " 'masami_test58.jpg',\n",
       " 'masami_test59.jpg',\n",
       " 'masami_test65.jpg',\n",
       " 'masami_test16.jpg',\n",
       " 'masami_test17.jpg',\n",
       " 'masami_test29.jpg',\n",
       " 'masami_test15.jpg',\n",
       " 'masami_test14.jpg',\n",
       " 'masami_test28.jpg',\n",
       " 'masami_test10.jpg',\n",
       " 'masami_test38.jpg',\n",
       " 'masami_test39.jpg',\n",
       " 'masami_test11.jpg',\n",
       " 'masami_test13.jpg',\n",
       " 'masami_test12.jpg',\n",
       " 'masami_test23.jpg',\n",
       " 'masami_test37.jpg',\n",
       " 'masami_test36.jpg',\n",
       " 'masami_test22.jpg',\n",
       " 'masami_test34.jpg',\n",
       " 'masami_test20.jpg',\n",
       " 'masami_test21.jpg',\n",
       " 'masami_test35.jpg',\n",
       " 'masami_test31.jpg',\n",
       " 'masami_test25.jpg',\n",
       " 'masami_test19.jpg',\n",
       " 'masami_test18.jpg',\n",
       " 'masami_test24.jpg',\n",
       " 'masami_test30.jpg',\n",
       " 'masami_test26.jpg',\n",
       " 'masami_test32.jpg',\n",
       " 'masami_test33.jpg',\n",
       " 'masami_test27.jpg',\n",
       " 'masami_test68.jpg',\n",
       " 'masami_test40.jpg',\n",
       " 'masami_test54.jpg',\n",
       " 'masami_test1.jpg',\n",
       " 'masami_test55.jpg',\n",
       " 'masami_test41.jpg',\n",
       " 'masami_test69.jpg',\n",
       " 'masami_test57.jpg',\n",
       " 'masami_test43.jpg',\n",
       " 'masami_test2.jpg',\n",
       " 'masami_test3.jpg',\n",
       " 'masami_test42.jpg',\n",
       " 'masami_test56.jpg',\n",
       " 'masami_test52.jpg',\n",
       " 'masami_test46.jpg',\n",
       " 'masami_test7.jpg',\n",
       " 'masami_test6.jpg',\n",
       " 'masami_test47.jpg',\n",
       " 'masami_test53.jpg',\n",
       " 'masami_test45.jpg',\n",
       " 'masami_test51.jpg',\n",
       " 'masami_test4.jpg',\n",
       " 'masami_test5.jpg',\n",
       " 'masami_test50.jpg',\n",
       " 'masami_test44.jpg']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#リストの確認\n",
    "pic_masami2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#画像・ラベルを配列に格納する(訓練用画像)\n",
    "#長澤まさみ：0、有村架純：1、浜辺美波：２\n",
    "\n",
    "datas_pic = []\n",
    "datas_label = []\n",
    "\n",
    "#長澤まさみの画像を配列に格納する\n",
    "for i in pic_masami2:\n",
    "    #写真格納\n",
    "    #写真をdataに格納する\n",
    "    data = np.array(Image.open(masami_jpg + i).convert(\"L\"), np.float32)\n",
    "    #画像の形式を(100,100)→(1,100,100)に変更\n",
    "    data = data.reshape(-1,100,100)\n",
    "    #画像の次元を追加（axisに指定した成分に次元を追加）\n",
    "    data_expanded = np.expand_dims(data,axis=0)\n",
    "    #画像を配列に格納する\n",
    "    datas_pic.append(data_expanded)\n",
    "    #Numpy配列に格納する\n",
    "    train_datas = np.concatenate(datas_pic,axis=0)\n",
    "    #ラベル格納\n",
    "    label = 0\n",
    "    #ラベルの次元を追加する\n",
    "    label_expanded = np.expand_dims(label,axis=0)\n",
    "    #ラベルを配列に格納する\n",
    "    datas_label.append(label_expanded)\n",
    "    #Numpy配列に格納する\n",
    "    label_datas = np.concatenate(datas_label,axis=0)\n",
    "    \n",
    "#有村架純の画像を配列に格納する\n",
    "for i in pic_kasumi2:\n",
    "    #写真をdataに格納する\n",
    "    data = np.array(Image.open(kasumi_jpg + i).convert(\"L\"), np.float32)\n",
    "    #形式を(100,100)→(1,100,100)に変更\n",
    "    data = data.reshape(-1,100,100)\n",
    "    #次元を追加（axisに指定した成分に次元を追加）\n",
    "    data_expanded = np.expand_dims(data,axis=0)\n",
    "    #配列に格納する\n",
    "    datas_pic.append(data_expanded)\n",
    "    train_datas = np.concatenate(datas_pic,axis=0)\n",
    "    #ラベル格納\n",
    "    label = 1\n",
    "    #ラベルの次元を追加する\n",
    "    label_expanded = np.expand_dims(label,axis=0)\n",
    "    #ラベルを配列に格納する\n",
    "    datas_label.append(label_expanded)\n",
    "    #Numpy配列に格納する\n",
    "    label_datas = np.concatenate(datas_label,axis=0)\n",
    "\n",
    "#浜辺美波の画像を配列に格納する\n",
    "for i in pic_minami2:\n",
    "    #写真格納\n",
    "    #写真をdataに格納する\n",
    "    data = np.array(Image.open(minami_jpg + i).convert(\"L\"), np.float32)\n",
    "    #画像の形式を(100,100)→(1,100,100)に変更\n",
    "    data = data.reshape(-1,100,100)\n",
    "    #画像の次元を追加（axisに指定した成分に次元を追加）\n",
    "    data_expanded = np.expand_dims(data,axis=0)\n",
    "    #画像を配列に格納する\n",
    "    datas_pic.append(data_expanded)\n",
    "    #Numpy配列に格納する\n",
    "    train_datas = np.concatenate(datas_pic,axis=0)\n",
    "    #ラベル格納\n",
    "    label = 2\n",
    "    #ラベルの次元を追加する\n",
    "    label_expanded = np.expand_dims(label,axis=0)\n",
    "    #ラベルを配列に格納する\n",
    "    datas_label.append(label_expanded)\n",
    "    #Numpy配列に格納する\n",
    "    label_datas = np.concatenate(datas_label,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_test,t_test)=(train_datas,label_datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(734, 1, 100, 100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_datas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "#(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 処理に時間のかかる場合はデータを削減 \n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "class SimpleConvNet:\n",
    "    \"\"\"単純なConvNet\n",
    "\n",
    "    conv - relu - pool - affine - relu - affine - softmax\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : 入力サイズ（MNISTの場合は784）\n",
    "    hidden_size_list : 隠れ層のニューロンの数のリスト（e.g. [100, 100, 100]）\n",
    "    output_size : 出力サイズ（MNISTの場合は10）\n",
    "    activation : 'relu' or 'sigmoid'\n",
    "    weight_init_std : 重みの標準偏差を指定（e.g. 0.01）\n",
    "        'relu'または'he'を指定した場合は「Heの初期値」を設定\n",
    "        'sigmoid'または'xavier'を指定した場合は「Xavierの初期値」を設定\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 100, 100), \n",
    "                 conv_param={'filter_num':30, 'filter_size':7, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=3, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 重みの初期化\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"損失関数を求める\n",
    "        引数のxは入力データ、tは教師ラベル\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        \"\"\"勾配を求める（数値微分）\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 入力データ\n",
    "        t : 教師ラベル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        各層の勾配を持ったディクショナリ変数\n",
    "            grads['W1']、grads['W2']、...は各層の重み\n",
    "            grads['b1']、grads['b2']、...は各層のバイアス\n",
    "        \"\"\"\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"勾配を求める（誤差逆伝搬法）\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 入力データ\n",
    "        t : 教師ラベル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        各層の勾配を持ったディクショナリ変数\n",
    "            grads['W1']、grads['W2']、...は各層の重み\n",
    "            grads['b1']、grads['b2']、...は各層のバイアス\n",
    "        \"\"\"\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 設定\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:8.703771605517495\n",
      "=== epoch:1, train acc:0.2901907356948229, test acc:0.0 ===\n",
      "train loss:8.254071070947042\n",
      "train loss:11.018232764407028\n",
      "train loss:6.435580229669902\n",
      "train loss:1.7615776484400356\n",
      "train loss:1.417654806412453\n",
      "train loss:1.3286813993071949\n",
      "train loss:1.207410730900513\n",
      "train loss:1.0807317707574027\n",
      "train loss:1.0636158628555585\n",
      "train loss:1.089892814177042\n",
      "train loss:1.087090045240761\n",
      "train loss:1.09643823201172\n",
      "train loss:1.0988067166650983\n",
      "train loss:1.096862549559205\n",
      "train loss:1.0969816068460467\n",
      "train loss:1.0989137911016182\n",
      "train loss:1.0977151553061082\n",
      "train loss:1.094911117110518\n",
      "train loss:1.0890505774123314\n",
      "train loss:1.0530302852017015\n",
      "train loss:1.084642813381141\n",
      "train loss:1.052291400993351\n",
      "train loss:1.088376331349549\n",
      "train loss:1.0886749932382105\n",
      "train loss:1.0973643887218116\n",
      "train loss:1.096515398828855\n",
      "train loss:1.0985251914641485\n",
      "train loss:1.099212582958579\n",
      "train loss:1.098309981891476\n",
      "train loss:1.0982784574158997\n",
      "train loss:1.0976017021741789\n",
      "train loss:1.098685837294908\n",
      "train loss:1.099241432912746\n",
      "train loss:1.0980534004062017\n",
      "train loss:1.0987668164973783\n",
      "train loss:1.0990357974659954\n",
      "train loss:1.098114384514914\n",
      "train loss:1.099069523457594\n",
      "train loss:1.0987867567519713\n",
      "train loss:1.098261641666867\n",
      "train loss:1.0980837876839482\n",
      "train loss:1.097803286138233\n",
      "train loss:1.0979865917291307\n",
      "train loss:1.0982524266472993\n",
      "train loss:1.0984472963060945\n",
      "train loss:1.0961752803763387\n",
      "train loss:1.0963152520362736\n",
      "train loss:1.0869041115163496\n",
      "train loss:1.092265075288026\n",
      "train loss:1.0885408078089727\n",
      "train loss:1.0607877809800381\n",
      "train loss:1.0557078898304149\n",
      "train loss:0.9402093135324431\n",
      "train loss:1.0059079326605374\n",
      "train loss:1.0138872535428463\n",
      "train loss:1.0427362836330374\n",
      "train loss:1.0503516744142134\n",
      "train loss:1.026140831171503\n",
      "train loss:1.036356158339828\n",
      "train loss:1.0217303899967294\n",
      "train loss:1.0191182874678484\n",
      "train loss:0.9756450526259701\n",
      "train loss:1.0211110011036892\n",
      "train loss:0.7853121345910382\n",
      "train loss:0.8385759773134257\n",
      "train loss:0.7252949016594122\n",
      "train loss:0.8058998792925399\n",
      "train loss:0.9020098190773838\n",
      "train loss:0.9102769513250816\n",
      "train loss:0.9734209624769181\n",
      "train loss:1.0565363305280335\n",
      "train loss:0.9756324418677177\n",
      "train loss:0.9282974265881883\n",
      "train loss:0.8029594186373776\n",
      "train loss:0.8010030756328891\n",
      "train loss:0.8252351300842931\n",
      "train loss:0.8200490149960412\n",
      "train loss:0.8532851331282744\n",
      "train loss:0.8478669901378896\n",
      "train loss:0.767392578090744\n",
      "train loss:0.6755608468112733\n",
      "train loss:0.7118152115109089\n",
      "train loss:0.46831716893847586\n",
      "train loss:0.6179659140591193\n",
      "train loss:0.4303312847497128\n",
      "train loss:0.6809350104679818\n",
      "train loss:0.5662834888311316\n",
      "train loss:0.7316776536945372\n",
      "train loss:0.8103976193162404\n",
      "train loss:0.8287128423757483\n",
      "train loss:0.8961000630292291\n",
      "train loss:0.9202557095770427\n",
      "train loss:0.9244581380960321\n",
      "train loss:0.8393655318258607\n",
      "train loss:0.7972625644152065\n",
      "train loss:0.8209364007797331\n",
      "train loss:0.8685296780814737\n",
      "train loss:0.5607532239254666\n",
      "train loss:0.7890669290142138\n",
      "train loss:0.8851745979548198\n",
      "train loss:0.6330359314401927\n",
      "train loss:0.7196323535949561\n",
      "train loss:0.5422365205063965\n",
      "train loss:0.420903599437811\n",
      "train loss:0.5062528131050804\n",
      "train loss:0.5435653925067099\n",
      "train loss:0.5150222082118989\n",
      "train loss:0.39681309727191305\n",
      "train loss:0.5159265686691239\n",
      "train loss:0.5940935479292083\n",
      "train loss:0.5780008665503\n",
      "train loss:0.4335883227648181\n",
      "train loss:0.4776859752921163\n",
      "train loss:0.4900842158343723\n",
      "train loss:0.48470263788686707\n",
      "train loss:0.43798492294468905\n",
      "train loss:0.3974528001010836\n",
      "train loss:0.32243864362558305\n",
      "train loss:0.4297261248502967\n",
      "train loss:0.39899411431652504\n",
      "train loss:0.3314278417884873\n",
      "train loss:0.4188866623826913\n",
      "train loss:0.43759437888179925\n",
      "train loss:0.358958752196848\n",
      "train loss:0.4587614576512773\n",
      "train loss:0.2766128995134581\n",
      "train loss:0.34412705359920454\n",
      "train loss:0.30649620183604875\n",
      "train loss:0.4721659618275808\n",
      "train loss:0.46170537141416246\n",
      "train loss:0.38619751689404824\n",
      "train loss:0.2760896901846857\n",
      "train loss:0.3406309460790625\n",
      "train loss:0.36176423767086796\n",
      "train loss:0.3787116838495457\n",
      "train loss:0.4835389723459796\n",
      "train loss:0.28676253150766207\n",
      "train loss:0.12461532452598824\n",
      "train loss:0.33663797168222886\n",
      "train loss:0.18755653653634866\n",
      "train loss:0.17367817468391078\n",
      "train loss:0.2891010675741701\n",
      "train loss:0.22945484129875268\n",
      "train loss:0.24520687841561234\n",
      "train loss:0.2334048609217304\n",
      "train loss:0.23575714115802668\n",
      "train loss:0.30389535348891095\n",
      "train loss:0.3326561003895032\n",
      "train loss:0.19890099210068624\n",
      "train loss:0.17472244046771107\n",
      "train loss:0.14849619288296595\n",
      "train loss:0.14118762075829316\n",
      "train loss:0.15582481076698618\n",
      "train loss:0.175618930551977\n",
      "train loss:0.22520168856109288\n",
      "train loss:0.18528322404289338\n",
      "train loss:0.23330263651795036\n",
      "train loss:0.10864225959871955\n",
      "train loss:0.13621410676868811\n",
      "train loss:0.11719352929185206\n",
      "train loss:0.12253597655057939\n",
      "train loss:0.13303701159070822\n",
      "train loss:0.14221456069004548\n",
      "train loss:0.12392076173446348\n",
      "train loss:0.06707363882324803\n",
      "train loss:0.10840742895814862\n",
      "train loss:0.05846195846322292\n",
      "train loss:0.11324227096016902\n",
      "train loss:0.19593489991242494\n",
      "train loss:0.1597697439545439\n",
      "train loss:0.05792266658636202\n",
      "train loss:0.07404137886546341\n",
      "train loss:0.06386901005414447\n",
      "train loss:0.1062112346965451\n",
      "train loss:0.04053875582577964\n",
      "train loss:0.04282523648135808\n",
      "train loss:0.05747466764632207\n",
      "train loss:0.08931630781090108\n",
      "train loss:0.042731308011675295\n",
      "train loss:0.08264792394373158\n",
      "train loss:0.08278599173826233\n",
      "train loss:0.09313288805914993\n",
      "train loss:0.04628851907119302\n",
      "train loss:0.13589457168335917\n",
      "train loss:0.03876210133118101\n",
      "train loss:0.02418686515372291\n",
      "train loss:0.16230148038247505\n",
      "train loss:0.1877818175161818\n",
      "train loss:0.2179108665974122\n",
      "train loss:0.18355542868964803\n",
      "train loss:0.19338313582848435\n",
      "train loss:0.1520851607321236\n",
      "train loss:0.13789950377675164\n",
      "train loss:0.13344335676427424\n",
      "train loss:0.07393237240902156\n",
      "train loss:0.08232963520867624\n",
      "train loss:0.043375777088413656\n",
      "train loss:0.03243462405090925\n",
      "train loss:0.06870328363509805\n",
      "train loss:0.0973345618457953\n",
      "train loss:0.11640611095688916\n",
      "train loss:0.2469779480813531\n",
      "train loss:0.1795948604337634\n",
      "train loss:0.26438851024556403\n",
      "train loss:0.1385523658711947\n",
      "train loss:0.16703193987993165\n",
      "train loss:0.10413893683652234\n",
      "train loss:0.07141646984198426\n",
      "train loss:0.08128280120114832\n",
      "train loss:0.07369638265626365\n",
      "train loss:0.03147553215855669\n",
      "train loss:0.04791395667996914\n",
      "train loss:0.050650925179998973\n",
      "train loss:0.06428292671415663\n",
      "train loss:0.0628865250746543\n",
      "train loss:0.03990312386546155\n",
      "train loss:0.10179029936980542\n",
      "train loss:0.025397429549695635\n",
      "train loss:0.03000514512322698\n",
      "train loss:0.060794920982837904\n",
      "train loss:0.04153517768133178\n",
      "train loss:0.08634124194555852\n",
      "train loss:0.04701930255258713\n",
      "train loss:0.03171329707975145\n",
      "train loss:0.04459470610143518\n",
      "train loss:0.042680979021104265\n",
      "train loss:0.02814939157600013\n",
      "train loss:0.015484600414641437\n",
      "train loss:0.006214362440047292\n",
      "train loss:0.008243615084290556\n",
      "train loss:0.025628830064823825\n",
      "train loss:0.01587608064829737\n",
      "train loss:0.07742210474440793\n",
      "train loss:0.016569432785344868\n",
      "train loss:0.03264078038083788\n",
      "train loss:0.028145408473920788\n",
      "train loss:0.005538057736496246\n",
      "train loss:0.015067460928843123\n",
      "train loss:0.013515057317644286\n",
      "train loss:0.016739162412157366\n",
      "train loss:0.01246830678354542\n",
      "train loss:0.009773486201477362\n",
      "train loss:0.019880707951018647\n",
      "train loss:0.008080811195859551\n",
      "train loss:0.00773954504467609\n",
      "train loss:0.008945456384655253\n",
      "train loss:0.014722334232235346\n",
      "train loss:0.009866749306429303\n",
      "train loss:0.008027824590549962\n",
      "train loss:0.010187618531561827\n",
      "train loss:0.014837967205679495\n",
      "train loss:0.016706662171594253\n",
      "train loss:0.023510916004492653\n",
      "train loss:0.010566883130199276\n",
      "train loss:0.00497192101659106\n",
      "train loss:0.013706619355584069\n",
      "train loss:0.01565557335000908\n",
      "train loss:0.013334687094404935\n",
      "train loss:0.015628135853450374\n",
      "train loss:0.016235414599140057\n",
      "train loss:0.017622148048998885\n",
      "train loss:0.008368218971865021\n",
      "train loss:0.007760848621309795\n",
      "train loss:0.013900428907268749\n",
      "train loss:0.006325311980194287\n",
      "train loss:0.006536555713076133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004717974423554217\n",
      "train loss:0.012499558700690803\n",
      "train loss:0.007567569204924026\n",
      "train loss:0.0033911478202644243\n",
      "train loss:0.009597841320902922\n",
      "train loss:0.006514493324630024\n",
      "train loss:0.0009245650383867657\n",
      "train loss:0.0033314300196701317\n",
      "train loss:0.042947011691887915\n",
      "train loss:0.009712797350464333\n",
      "train loss:0.004592101073625356\n",
      "train loss:0.0055513620096405945\n",
      "train loss:0.006458866124302973\n",
      "train loss:0.00980056245379179\n",
      "train loss:0.003387879173238935\n",
      "train loss:0.01003342885441305\n",
      "train loss:0.005803750580489334\n",
      "train loss:0.006114564978324011\n",
      "train loss:0.017151166356508752\n",
      "train loss:0.004698994740163185\n",
      "train loss:0.006373479271259875\n",
      "train loss:0.0102545478102531\n",
      "train loss:0.011724498137525028\n",
      "train loss:0.004395716181400499\n",
      "train loss:0.010903252112093198\n",
      "train loss:0.010183179365737989\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.4470588235294118\n",
      "Saved Network Parameters!\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,100,100), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 7, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=3, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=50,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# パラメータの保存\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (20,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-8100ed1de23e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m's'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkevery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m's'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkevery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \"\"\"\n\u001b[1;32m   1645\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (20,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " # グラフの描画\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
